{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user.oc-static.com/upload/2019/10/22/15717382019055_Capture%20d%E2%80%99e%CC%81cran%202019-10-22%20a%CC%80%2011.50.29.png\">\n",
    "\n",
    "\n",
    "\n",
    "# Déploiement d'un modèle \n",
    "\n",
    "Dans cette partie, nous déploierons le modèle LSTM bidirectionnel contenant la couche d'embedding keras sur les services de Microsoft Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1644523680252
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécéssaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from utils import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from azureml.core import Workspace\n",
    "\n",
    "\n",
    "data_folder = os.path.join(os.getcwd(), \"/tmp/qs_data\")\n",
    "os.makedirs(data_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1644523686078
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import du jeu de données\n",
    "df_ = pd.read_csv('/utile/data.csv')\n",
    "\n",
    "# Constitution du dictionnaire \n",
    "dct = Dictionary(df_.text.apply(lambda x: x.lower().split()))\n",
    "\n",
    "def return_index(X):\n",
    "    keys = dct.token2id.keys()\n",
    "    \n",
    "    tokens = []\n",
    "    for x in X.lower().split():\n",
    "        if x in keys:\n",
    "            tokens.append(dct.token2id[x])\n",
    "    return tokens\n",
    "\n",
    "\n",
    "y = df_.label\n",
    "X = sequence.pad_sequences(df_.text.apply(return_index),\n",
    "                                 value=0,\n",
    "                                 padding='post', # to add zeros at the end\n",
    "                                 truncating='post', # to cut the end of long sequences\n",
    "                                 maxlen=32) # the length we want\n",
    "\n",
    "# Séparation du jeu de données en jeu de données d'entrainement et de validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Création du modèle LSTM bidirectionnelle\n",
    "def my_LSTM5(len_dict):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len_dict, output_dim=12, input_length=32))\n",
    "    model.add(Bidirectional(LSTM(units=8, return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(units=8, return_sequences=False)))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "model5 = my_LSTM5(len(dct))\n",
    "model5.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1644523796136
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/02/10 20:08:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2022/02/10 20:08:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "2022/02/10 20:08:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "2022/02/10 20:08:08 INFO mlflow.pyspark.ml: No SparkSession detected. Autologging will log pyspark.ml models contained in the default allowlist. To specify a custom allowlist, initialize a SparkSession prior to calling mlflow.pyspark.ml.autolog() and specify the path to your allowlist file via the spark.mlflow.pysparkml.autolog.logModelAllowlistFile conf.\n",
      "2022/02/10 20:08:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.ml.\n",
      "Using TensorFlow backend.\n",
      "2022/02/10 20:09:32 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: module 'tensorflow_core.compat.v2' has no attribute '__internal__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/dct.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Connection à l'espace de travail d'Azure\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# create experiment and start logging to a new run in the experiment\n",
    "name = \"model5-LSTM\"\n",
    "\n",
    "# set up MLflow to track the metrics\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "mlflow.set_experiment(name)\n",
    "mlflow.autolog()\n",
    "\n",
    "\n",
    "# Entrainement du modèle\n",
    "with mlflow.start_run() as run:\n",
    "    model5.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, verbose=0)\n",
    "\n",
    "# sauvegarde du modèle et du dictionnaire\n",
    "model5.save('./utile/model')\n",
    "joblib.dump(dct,\"./utile/model/dct.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1644523848873
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model Model_deep\n",
      "Registering model dct\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "# Sauvegarde des modèle dans l'espacce de travail d'Azure\n",
    "model = Model.register(model_path=\"./utile/model\",\n",
    "                       model_name=\"Model_deep\",\n",
    "                       tags={'area': \"NLP\", 'type': \"tokenizer\"},\n",
    "                       description=\"First Model save\",\n",
    "                       workspace=ws)\n",
    "\n",
    "dct = Model.register(model_path=\"./utile/model/dct.pkl\",\n",
    "                       model_name=\"dct\",\n",
    "                       tags={'area': \"NLP\", 'type': \"Dict\"},\n",
    "                       description=\"Dictionary of tokens\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1644523848966
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Création des ressource environements de déploiement\n",
    "source_directory = \"./utile/dependances\"\n",
    "\n",
    "env_tf_sk = Environment('tensorflow-scikit')\n",
    "env_tf_sk.python.conda_dependencies.add_pip_package(\"azureml-core\")\n",
    "env_tf_sk.python.conda_dependencies.add_pip_package(\"gensim\")\n",
    "env_tf_sk.python.conda_dependencies.add_pip_package(\"joblib\")\n",
    "env_tf_sk.python.conda_dependencies.add_pip_package(\"scikit-learn\")\n",
    "env_tf_sk.python.conda_dependencies.add_pip_package(\"tensorflow\")\n",
    "\n",
    "\n",
    "inference_config = InferenceConfig(source_directory=source_directory,\n",
    "                                   entry_script=\"./utile/y/score.py\",\n",
    "                                   environment=env_tf_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1644524393984
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-02-10 20:16:26+00:00 Creating Container Registry if not exists.\n",
      "2022-02-10 20:16:26+00:00 Registering the environment.\n",
      "2022-02-10 20:16:27+00:00 Use the existing image.\n",
      "2022-02-10 20:16:27+00:00 Generating deployment configuration.\n",
      "2022-02-10 20:16:29+00:00 Submitting deployment to compute.\n",
      "2022-02-10 20:16:33+00:00 Checking the status of deployment model5..\n",
      "2022-02-10 20:19:22+00:00 Checking the status of inference endpoint model5.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Configuration du déploiement\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 4,auth_enabled=True)\n",
    "\n",
    "# Création d'une instance de déploiement\n",
    "service = Model.deploy(\n",
    "    workspace = ws,\n",
    "    name = \"model5\",\n",
    "    models = [dct, model],\n",
    "    inference_config = inference_config,\n",
    "    deployment_config = deployment_config)\n",
    "\n",
    "# Déploiement du modèle\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1644524394389
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddAFENhn8UuDsK9vnims8PWUWcP1ge41\n",
      "http://0b15f0b2-7c89-4e2d-8036-33a163069b86.westeurope.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "# Affichage des identifiant de connexion\n",
    "primary, secondary = service.get_keys()\n",
    "print(primary)\n",
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1644524620198
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5396204844364547e-07], [1.5396204844364547e-07], [1.5396204844364547e-07]]\n"
     ]
    }
   ],
   "source": [
    "# Appel de la fonction\n",
    "import json\n",
    "input_payload = json.dumps({\n",
    "    'data': [\"bad I hate horible\", \"Hello world good hapy\", \"bad\"],\n",
    "    'method':\"prediction_with_neutral\"\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=int32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test de la fonction\n",
    "from functions import *\n",
    "get_model(['Good', 'Bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "À l'issue de notre analyse comparative des différentes propositions d'approche permettant de détecter le sentiment négatif associé à un tweet, nous pouvons déterminer quel modèle sera le plus adapté.\n",
    "\n",
    "Pour la construction d'un modèle de A à Z la solution deeplearning LSTM bidirectionnel avec couche d'embedding offre une maîtrise complète de son modèle avec des temps de calcul relativement important pour la phase d'entraînement qui sont ensuite quasi inexistants dans la phase de prédiction contrairement aux approches API sur étagère ou API sur-mesure simple. De plus, le déploiement du modèle complète les caractéristiques de cette approche bien que cette démarche se révèle la plus technique à mettre en place."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
